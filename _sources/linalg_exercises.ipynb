{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d2cbf3",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Linear Algebra Trivia\n",
    "\n",
    "1. $A\\in\\mathbb{R}^{n\\times r}$, $B\\in\\mathbb{R}^{m\\times r}$, which product is well-defined?    \n",
    "    A.  $BA$    \n",
    "    B.  $A^\\top B$    \n",
    "    C.  $AB^\\top$    \n",
    "    ```{toggle}\n",
    "    The correct solution is C. $AB^\\top$, the connecting dimension is $r$. \n",
    "    ```\n",
    "2. $A\\in\\mathbb{R}^{n\\times r}$, $B\\in\\mathbb{R}^{m\\times r}$, what is equal to $(AB^\\top)^\\top ?$     \n",
    "    A. $A^\\top B$     \n",
    "    B. $B^\\top A^\\top$     \n",
    "    C. $BA^\\top$    \n",
    "    ```{toggle}\n",
    "    The correct solution is C. $BA^\\top$, we have $(AB^\\top)^\\top = {B^\\top}^\\top A^\\top = BA^\\top$.\n",
    "    ```\n",
    "3. What is the matrix product computed by $C_{ji}=\\sum_{s=1}^rA_{is}B_{js} ?$     \n",
    "    A. $C=AB^\\top$     \n",
    "    B. $C=B^\\top A$     \n",
    "    C. $C=BA^\\top$ \n",
    "    ```{toggle}\n",
    "    The correct solution is C. $BA^\\top$, we have \n",
    "    $C_{ji}=\\sum_{s=1}^rA_{is}B_{js} = \\sum_{s=1}^rB_{js}A_{is} = B_{j\\cdot}A_{i\\cdot}^\\top$, hence $C=BA^\\top$.\n",
    "    ```\n",
    "4. $A,B\\in\\mathbb{R}^{n\\times n}$ have an inverse $A^{-1},B^{-1}$, what is generally **not** equal to $AA^{-1}B$?    \n",
    "    A. $A^{-1}BA$     \n",
    "    B. $B$       \n",
    "    C. $BB^{-1}B$ \n",
    "    ```{toggle}\n",
    "    The correct answer is A. $A^{-1}BA$, since the matrix product between the matrices $A^{-1}$ and $BA$ is generally not commutative. Answers B. and C. are correct because\n",
    "    $$AA^{-1}B = IB =B = BB^{-1}B.$$\n",
    "    ```\n",
    "5. Let $v,w\\in\\mathbb{R}^{d}$, $\\alpha\\in\\mathbb{R}$, then $\\lVert\\alpha v + w\\rVert\\leq$    \n",
    "    A. $\\alpha\\lVert v+w\\rVert$     \n",
    "    B. $\\lvert\\alpha\\rvert\\lVert v\\rVert+\\lVert w\\rVert$     \n",
    "    C. $\\alpha\\lVert v\\rVert+\\lVert w\\rVert$\n",
    "    ```{toggle}\n",
    "    The correct answer is B. $\\lvert\\alpha\\rvert\\lVert v\\rVert+\\lVert w\\rVert$, because \n",
    "    \\begin{align*}\n",
    "    \\lVert\\alpha v + w\\rVert&\\leq \\lVert\\alpha v\\rVert + \\lVert w\\rVert  &\\text{(triangle inequality)}\\\\\n",
    "    & = \\lvert\\alpha\\rvert\\lVert v\\rVert + \\lVert w\\rVert  &\\text{(homogenity)}.\n",
    "    \\end{align*}\n",
    "    ```\n",
    "6. Let $A,B\\in\\mathbb{R}^{n\\times r}$, $\\alpha\\in\\mathbb{R}$, then $\\lVert A\\rVert\\leq$\n",
    "    A. $\\lVert A-B\\rVert + \\lVert B\\rVert$\n",
    "    B. $\\alpha\\lVert\\frac{1}{\\alpha}A\\rVert$\n",
    "    C. $\\lVert A\\rVert^2$\n",
    "    ```{toggle}\n",
    "    The correct answer is A. $\\lVert A-B\\rVert + \\lVert B\\rVert$, because\n",
    "    \\begin{align*}\n",
    "    \\lVert A\\rVert\\leq \\lVert A-B+B\\rVert \\leq \\lVert A -B \\rVert +\\lVert B\\rVert,\n",
    "    \\end{align*}\n",
    "    where the last inequality derives from the triangle inequality. Answer B. is nott correct because the inequalitty does not hold for negative $\\alpha$ and C. is not correct for matrices $A$ having small entries (for example take the $1\\times 1$ matrix A=(0.1), then $\\lVert A\\rVert = 0.1 > 0.1^2$).\n",
    "    ```\n",
    "7. Let $A,B\\in\\mathbb{R}^{n\\times n}$, $A$ is orthogonal, what is **not** equal to $\\tr(ABA^\\top)$?     \n",
    "    A. $\\tr(A^\\top BA)$    \n",
    "    B. $\\tr(B)$     \n",
    "    C. $\\tr(ABA)$      \n",
    "    ```{toggle}\n",
    "    The correct answer is C. $\\tr(ABA)$. The other answers are not correct because the cycling property of the trace yields $\\tr(ABA^\\top)  = \\tr(BA^\\top A)$, and\n",
    "    \\begin{align*}\n",
    "    \\tr(ABA^\\top) & = \\tr(BA^\\top A) = \\tr(BI) =\\tr(B) & \\text{(orthogonality of $A$)}\\\\\n",
    "    & = \\tr(IB) = \\tr(AA^\\top B) = \\tr(A^\\top B A). &\\text{(cycling property and orthogonality)}\n",
    "    \\end{align*}\n",
    "    ```\n",
    "## Exercises\n",
    "1. Compute the matrix product $AB$ inner-product-wise and outer-product-wise\n",
    "    \\begin{align*}\n",
    "    A=\\begin{pmatrix} 1 & 2 & 0 \\\\\n",
    "    0 & 2& 4\\end{pmatrix},\\quad B=\\begin{pmatrix} 0 & 2 \\\\\n",
    "    3 &1 \\\\\n",
    "    1 & 2\\end{pmatrix}.\n",
    "    \\end{align*}\n",
    "    ```{toggle}\n",
    "    Computing the matrix product _inner product wise_:\n",
    "    \\begin{align*}\n",
    "    AB = \n",
    "    \\begin{pmatrix}\n",
    "        1\\cdot 0 + 2\\cdot3+0\\cdot 1 & 1\\cdot2+2\\cdot1 + 0\\cdot 2\\\\\n",
    "        0\\cdot 0 + 2\\cdot3+4\\cdot 1 & 0\\cdot2+2\\cdot1 + 4\\cdot 2\n",
    "    \\end{pmatrix}\n",
    "    =\n",
    "    \\begin{pmatrix}\n",
    "        6 & 4\\\\\n",
    "        10 & 10\n",
    "    \\end{pmatrix}\n",
    "    \\end{align*}\n",
    "    Computing the matrix product _outer product wise_:\n",
    "    \\begin{align*}\n",
    "    AB &= \n",
    "    \\begin{pmatrix}1 \\\\0\\end{pmatrix}\\begin{pmatrix}0&2\\end{pmatrix} +\n",
    "    \\begin{pmatrix}2 \\\\2\\end{pmatrix}\\begin{pmatrix}3&1\\end{pmatrix} +\n",
    "    \\begin{pmatrix}0 \\\\4\\end{pmatrix}\\begin{pmatrix}1&2\\end{pmatrix} \\\\\n",
    "    &=\n",
    "    \\begin{pmatrix}1\\cdot 0 &  1\\cdot 2\\\\0\\cdot 0 & 0\\cdot 2\\end{pmatrix} +\n",
    "    \\begin{pmatrix}2\\cdot 3 & 2\\cdot 1 \\\\2\\cdot 3 & 2\\cdot 1\\end{pmatrix} +\n",
    "    \\begin{pmatrix}0\\cdot 1&0\\cdot2 \\\\4\\cdot1&4\\cdot2\\end{pmatrix}\\\\\n",
    "    &=\n",
    "    \\begin{pmatrix}0 &  2\\\\0 & 0\\end{pmatrix} +\n",
    "    \\begin{pmatrix}6 & 2 \\\\6 & 2\\end{pmatrix} +\n",
    "    \\begin{pmatrix}0&0 \\\\4&8\\end{pmatrix}\\\\\n",
    "    &= \\begin{pmatrix}6&4\\\\ 10 &10\\end{pmatrix}\n",
    "    \\end{align*}\n",
    "    ```\n",
    "2. You have observations of $5$ symptoms of a disease for three patients represented in the binary matrix \n",
    "    $$ A = \\begin{pmatrix}\n",
    "  1 & 0 & 1 & 1 & 0\\\\\n",
    "  1 & 1 & 0 & 0 & 0\\\\\n",
    "  0 & 1 & 0 & 0 & 1\\end{pmatrix}$$\n",
    "  Compute the matrix $AA^\\top$ and $A^\\top A$ and interpret the result with regard to the scenario.\n",
    "    ```{toggle}\n",
    "    The matrix represents a data table of the following format, where $\\mathtt{S}_i$ denotes the feature of sympton $i$ and $\\mathtt{P}$ stands for patient ID:\n",
    "    \n",
    "    |$\\mathtt{P}$| $\\mathtt{S}_1$ | $\\mathtt{S}_2$ | $\\mathtt{S}_3$ |  $\\mathtt{S}_4$ |  $\\mathtt{S}_5$ |\n",
    "    |------------|----------------|----------------|----------------|-----------------|-----------------|    \n",
    "    |1           | 1              | 0              | 1              | 1               |               0 | \n",
    "    |2|1 | 1 | 0  |0 | 0 |  \n",
    "    |3|0 | 1 | 0  |0 | 1 | \n",
    "    \n",
    "    The matrix products \n",
    "    \\begin{align*}\n",
    "        AA^\\top &= \n",
    "        \\begin{pmatrix}\n",
    "            3 & 1 & 0\\\\\n",
    "            1 & 2 & 1\\\\\n",
    "            0 & 1 & 2\n",
    "        \\end{pmatrix},\n",
    "        & A^\\top A &=\n",
    "        \\begin{pmatrix}\n",
    "            2 & 1 & 1 & 1 & 0\\\\\n",
    "            1 & 2 & 0 & 0 & 1\\\\\n",
    "            1 & 0 & 1 & 1 & 0\\\\\n",
    "            1 & 0 & 1 & 1 & 0\\\\\n",
    "            0 & 1 & 0 & 0 & 1\n",
    "        \\end{pmatrix}\n",
    "    \\end{align*}\n",
    "    contrast either the features or the patients. That is, the representation of the matrix product in the table format would look as follows:\n",
    "    \n",
    "    |$AA^\\top$ | $\\mathtt{P}_1$ | $\\mathtt{P}_2$ | $\\mathtt{P}_3$ |\n",
    "    |----------|----------------|----------------|----------------|\n",
    "    |$\\mathtt{P}_1$ |3 | 1 | 0  | \n",
    "    |$\\mathtt{P}_1$ |1 | 2 | 1  | \n",
    "    |$\\mathtt{P}_1$ |0 | 1 | 2  |\n",
    "    \n",
    "    |$A^\\top A$ | $\\mathtt{S}_1$ | $\\mathtt{S}_2$ | $\\mathtt{S}_3$ |  $\\mathtt{S}_4$ |  $\\mathtt{S}_5$ | \n",
    "    |-----------|----------------|----------------|----------------|-----------------|-----------------|\n",
    "    |$\\mathtt{S}_1$| 2 | 1 | 1  |1 | 0 |\n",
    "    |$\\mathtt{S}_2$| 1 | 2 | 0  |0 | 1 |\n",
    "    |$\\mathtt{S}_3$| 1 | 0 | 1  |1 | 0 |\n",
    "    |$\\mathtt{S}_4$| 1 | 0 | 1  |1 | 0 |\n",
    "    |$\\mathtt{S}_5$| 0 | 1 | 0  |0 | 1 |\n",
    "    \n",
    "    The table of $AA^\\top$ denotes in entry $jl$ the number of symptoms patient $j$ and patient $l$ have in common. The table of $A^\\top A$ denotes in entry $ik$ the number of patients which exibit symptoms $i$ and $k$.\n",
    "    ```\n",
    "3.  Find a matrix/vector notation to compute the vector of average feature values for a matrix $A\\in\\mathbb{R}^{n\\times d}$, representing $n$ observations of $d$ features. Make an example for your computation.\n",
    "    ```{toggle}\n",
    "     The vector representing the average for every feature value is computed by $\\bm{\\mu} = \\frac{1}{n} A^\\top \\mathbf{1}$ where $\\mathbf{1}$ is the $n$-dimensional one-vector, having all values equal to one. This is the case, because we have according to the definition of matrix multiplications by the row-times-column column scheme:\n",
    "     \\begin{align*}\n",
    "         \\bm{\\mu}^\\top = \\frac{1}{n}\\mathbf{1}^\\top A = \\frac1n \\begin{pmatrix}\\mathbf{1}^\\top A_{\\cdot 1} &\\ldots & \\mathbf{1}^\\top A_{\\cdot d}\\end{pmatrix},\n",
    "     \\end{align*}\n",
    "     that is, for $1\\leq j \\leq n$ we have that the $i$-th entry of $\\bm \\mu$ is given as\n",
    "     \\begin{align*}\n",
    "         \\bm\\mu_{i} = \\frac1n \\mathbf{1}^\\top A_{\\cdot i} = \\frac1n \\sum_{j=1}^n 1\\cdot A_{ji}= \\frac1n \\sum_{j=1}^n A_{ji},\n",
    "     \\end{align*}\n",
    "     which is equal to the average value for feature $i$.\n",
    "    ```\n",
    "4. Every system of linear equations can be written as a matrix equation $A\\vvec{x}=\\vvec{y}$. Given the following system of linear equations, what would be the matrix $A$ and vector $\\vvec{y}$ such that the system of linear equations is equivalent to solving $A\\vvec{x}=\\vvec{y}$? \n",
    "    \\begin{align}\n",
    "        2x_1 &+& 3x_2 && &=&4\\\\\n",
    "        x_1  &-& 2x_2 &+& x_3 &=& 3\\\\\n",
    "        -x_1 &+& 2x_2 &+& 3x_3 &=& 1\n",
    "    \\end{align}.\n",
    "    Can you solve the system of linear equations by using the inverse of $A$ (`np.linalg.inv(A)`)?  \n",
    "    ```{toggle}\n",
    "    You can easily verify that the equation $A\\vvec{x}=\\vvec{y}$ is equivalent to the above system of equations when using\n",
    "    \\begin{align*}\n",
    "        A &= \n",
    "        \\begin{pmatrix}\n",
    "            2 & 3 & 0\\\\\n",
    "            1 & -2 & 1\\\\\n",
    "            -1 & 2 & 3\n",
    "        \\end{pmatrix},\n",
    "        &y &= \n",
    "        \\begin{pmatrix}\n",
    "            4 \\\\\n",
    "            3 \\\\\n",
    "            1 \n",
    "        \\end{pmatrix}.\n",
    "    \\end{align*}\n",
    "    We can solve the system of linear equations by multiplying with $A^{-1}$ from left:\n",
    "    \\begin{align*}\n",
    "        A\\vvec{x}=\\vvec{y} \\Leftrightarrow A^{-1}A\\vvec{x}=A^{-1}\\vvec{y} \\Leftrightarrow \\vvec{x}=A^{-1}\\vvec{y}\n",
    "    \\end{align*}\n",
    "    That is, the solution is given by $\\vvec{x}=A^{-1}\\vvec{y}$. This is of course only possible if $A$ is invertible. In Python, we can solve the system of linear equations as follows:\n",
    "    \n",
    "        import numpy as np\n",
    "        A = np.array([[2,3,0],[1,-2,1],[-1,2,3]])\n",
    "        y = np.array([4,3,1])\n",
    "        print(\"x=\",np.linalg.inv(A)@y) \n",
    "    Alternatively, we can use the following function to solve a system of linear equations:\n",
    "    \n",
    "        print(\"x=\",np.linalg.solve(A,y))\n",
    "    ```\n",
    "4. Show that $\\lVert A - B \\rVert^2 = -2\\tr(AB^\\top) + 2n $ for orthogonal matrices $A,B\\in\\mathbb{R}^{n\\times n}$.\n",
    "    ```{toggle}\n",
    "    _Proof:_ Let $A,B\\in\\mathbb{R}^{n\\times n}$ be orthogonal matrices. Orthogonal matrices satisfy the property $AA^\\top =A^\\top A=I$ and $BB^\\top =B^\\top B=I$. Thus, we have\n",
    "    \\begin{align*}\n",
    "        \\lVert A-B\\rVert^2 &= \\lVert A\\rVert^2 -2\\tr(AB^\\top) + \\lVert B\\rVert^2 &\\text{(binomial formula for matrix norms)}\\\\\n",
    "        &= \\tr(A^\\top A) -2\\tr(AB^\\top) +\\tr(B^\\top B) &\\text{(definition of elementwise matrix $L_2$-norm)}\\\\\n",
    "        &= \\tr(I) -2\\tr(AB^\\top) +\\tr(I) &\\text{(orthogonality of $A$ and $B$)}\\\\\n",
    "        &= -2\\tr(AB^\\top) +2n, \n",
    "    \\end{align*}\n",
    "    because $\\tr(I) = \\underbrace{1 +\\ldots +1}_{n \\text{ times}} =n$. This concludes the proof.\n",
    "    ```\n",
    "5. Show that the following norms are orthogonal invariant\n",
    "    * the vector $L_2$-norm\n",
    "    * the Frobenius norm (matrix $L_2$-norm)\n",
    "    * the operator norm\n",
    "    ```{toggle}\n",
    "    A norm is orthogonal invariant if multiplying the argument with an orthogonal matrix from the left does not change the value of the norm. Let $A$ be a $(n\\times n)$ orthogonal matrix. For the $L_2$-norm of a vector $\\vvec{v}\\in\\mathbb{R}^n$ we have:\n",
    "    \\begin{align*}\n",
    "        \\lVert A\\vvec{v} \\rVert^2 &= (A\\vvec{v})^\\top A\\vvec{v} & \\text{(Definition)}\\\\ \n",
    "        &= \\vvec{v}^\\top A^\\top A\\vvec{v}\\\\ \n",
    "        &= \\vvec{v}^\\top \\vvec{v} &(A^\\top A =I)\\\\\n",
    "        &= \\lVert\\vvec{v}\\rVert^2\n",
    "    \\end{align*}\n",
    "    For the $L_2$-norm of a $(n\\times d)$ matrix $AD$ we have:\n",
    "    \\begin{align*}\n",
    "        \\lVert AD \\rVert^2 &= \\tr((AD)^\\top AD) &\\text{(Definition)}\\\\ \n",
    "        &= \\tr(D^\\top A^\\top AD) &\\\\ \n",
    "        &= \\tr(D^\\top D) & (A^\\top A=I)\\\\\n",
    "        &= \\lVert D\\rVert^2 &\n",
    "    \\end{align*}\n",
    "    For the operator norm of the matrix $AD$, we have:\n",
    "    \\begin{align*}\n",
    "        \\lVert AD \\rVert_{op} &= \\max_{\\vvec{x}:\\lVert\\vvec{x}\\rVert=1}\\lVert AD\\vvec{x}\\rVert &\\text{(Definition)}\\\\ \n",
    "        &= \\max_{\\vvec{x}:\\lVert\\vvec{x}\\rVert=1}\\lVert D\\vvec{x}\\rVert & \\text{(orthogonal invariance of $L_2$ vector norm)}\\\\ \n",
    "        &= \\lVert D\\rVert_{op} &\n",
    "    \\end{align*}\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
