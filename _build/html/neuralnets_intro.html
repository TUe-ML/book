
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Neural Networks Intro &#8212; Data Mining and Machine Learning Jupyter Book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"diag": "\\mathrm{diag}", "tr": "\\mathrm{tr}", "argmin": "\\mathrm{arg\\,min}", "argmax": "\\mathrm{arg\\,max}", "minimize": "\\mathrm{minimize}", "maximize": "\\mathrm{maximize}", "sgn": "\\mathrm{sgn}", "softmax": "\\mathrm{softmax}", "vvec": ["\\mathbf{#1}", 1], "bm": ["{\\boldsymbol #1}", 1], "concat": "\\mathbin{{+}\\mspace{-8mu}{+}}"}, "preamble": "\\usepackage{arydshln}"}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Computational graphs" href="neuralnets_comp_graphs.html" />
    <link rel="prev" title="Neural Networks" href="neuralnets.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Mining and Machine Learning Jupyter Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to the Data Mining and Machine Learning Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="notation.html">
   Notation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="linalg.html">
   Linear Algebra
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="linalg_spaces.html">
     Vector Spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linalg_normed_vs.html">
     Normed Vector Spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linalg_exercises.html">
     Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="optimization.html">
   Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="optimization_problems.html">
     Optimization Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optimization_numerical.html">
     Numerical Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optimization_convex.html">
     Convex Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optimization_gradients.html">
     Matrix Derivatives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optimization_exercises.html">
     Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="regression.html">
   Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="regression_objective.html">
     Regression Objective
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regression_functions.html">
     Regression Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regression_optimization.html">
     Minimizing the RSS
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regression_bias_var.html">
     The Bias-Variance Tradeoff
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regression_sparse.html">
     The Sparse Regression Task
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regression_ridge.html">
     Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regression_lasso.html">
     Lasso
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regression_L1vsL2.html">
     L1 vs L2 Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regression_exercises.html">
     Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="classification.html">
   Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="classification_problem.html">
     Classification Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification_evaluation.html">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification_knn.html">
     K-Nearest Neighbor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification_naive_bayes.html">
     NaÃ¯ve Bayes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification_decision_trees.html">
     Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification_random_forests.html">
     Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification_svms.html">
     Support Vector Machines
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="neuralnets.html">
   Neural Networks
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Neural Networks Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="neuralnets_comp_graphs.html">
     Computational graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="neuralnets_func_approx.html">
     Function approximator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="neuralnets_mlps.html">
     Multi-Layer Perceptrons
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="neuralnets_backprop.html">
     Backpropagation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="dim_reduction.html">
   Dimensionality Reduction Techniques
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="dim_reduction_mf.html">
     Low Rank Matrix Factorization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dim_reduction_matrix_completion.html">
     Matrix Completion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dim_reduction_pca.html">
     Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dim_reduction_exercises.html">
     Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="clustering.html">
   Clustering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="clustering_k_means.html">
     k-Means
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="clustering_k_means_mf.html">
     k-Means is MF
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="clustering_kernel_kmeans.html">
     Kernel k-means
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="clustering_spectral.html">
     Spectral Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="clustering_exercises.html">
     Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://gitlab.tue.nl/20214358/dmml"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://gitlab.tue.nl/20214358/dmml/issues/new?title=Issue%20on%20page%20%2Fneuralnets_intro.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/20214358/dmml/edit/master/neuralnets_intro.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/neuralnets_intro.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#biological-neural-networks">
   Biological neural networks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#artificial-neural-networks-anns">
   Artificial neural networks (ANNs)
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Neural Networks Intro</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#biological-neural-networks">
   Biological neural networks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#artificial-neural-networks-anns">
   Artificial neural networks (ANNs)
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="neural-networks-intro">
<h1>Neural Networks Intro<a class="headerlink" href="#neural-networks-intro" title="Permalink to this headline">#</a></h1>
<p>This section introduces the Artificial Neural Networks (ANNs).</p>
<section id="biological-neural-networks">
<h2>Biological neural networks<a class="headerlink" href="#biological-neural-networks" title="Permalink to this headline">#</a></h2>
<p>The human brain can be roughly divided into an old brain and a new brain on top of the old one. The old brain encompasses several old â€“ in developmental terms â€“ structures which are responsible for specific, mostly <em>unconscious</em> tasks such as breathing and temperature controlling. It also provides quick responses towards the individual survival and therefore plays a major role on basic feelings like fear, anger, etc. Most of the time, we are not even aware that these tasks are being managed by our old brain. On the other hand, the new brain is responsible for executing higher level tasks that typically requires slower responses and eventually can bring our <em>attention</em>:</p>
<ul class="simple">
<li><p>creating an internal representation of the external world;</p></li>
<li><p>performing higher-level reasoning and decision making;</p></li>
<li><p>creating and maintaining memories of events, facts;</p></li>
<li><p>following this fascinating piece of text ðŸ˜‰;</p></li>
<li><p>among many other high-level tasks.</p></li>
</ul>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The old brain prevents us from killing ourselves unintentionally everyday e.g. by waiting too long to run away from a hungry beast.</p>
</div>
</aside>
<p>The new brain comprises several structures that runs on the top of the old brain. One can think of the old brain as an <em>operational system</em> in modern computers which takes care of hardware-specific issues, whereas the new brain are more like software applications that runs on the top of the operational system and take benefit of all hardware-independent facilities provided by it. Keep in mind though that the implications of this weak analogy stops right there.</p>
<p>The neocortex is the most prominent structure of the new brain and it is paramount for such high-level tasks. The neocortex is so important that some researchers claim that we are our neocortexes <span id="id1">[]</span>. Anatomically, the neocortex consists of the commonly named <em>gray matter</em> surrounding the entire cortex of mammalian brains. In primates, it has deep grooves (sulci) and wrinkles (gyri) so that it fits the skull despite its huge size. If completed stretched out (unfolded), the human neocortex is approximately the size and the shape of a thick napkin which covers the deeper white matter in the brain. In contrast with the structures of the old brain, the neocortex has a surprisingly homogeneous arrangement of neuronal cells. More specifically, cortical cells are arranged in layers â€“ six layers in human brain â€“ and are mostly grouped in the so-called cortical columns over the external neocortex sheet. However, we do not fully understand today how these layers interact exactly within cortical columns or how the cortical columns interact with nearby â€“ same neocortex region â€“ and far way â€“ different neocortex regions â€“ cortical columns.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Some researchers <span id="id2">[]</span> go further and claim that the 6-layer neuronal circuit within cortical columns is the basic modular circuit replicated everywhere in the neocortex which runs a common <em>algorithm</em> to deal with all kind of tasks e.g. sensorial and motor tasks.</p>
</div>
</aside>
<figure class="align-left" id="neocortex-fig">
<a class="reference internal image-reference" href="_images/neocortex.jpg"><img alt="_images/neocortex.jpg" src="_images/neocortex.jpg" style="height: 320px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 36 </span><span class="caption-text">The neocortex (adapted from <span id="id3">[]</span>).</span><a class="headerlink" href="#neocortex-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The grayish aspect of this <em>sheet</em> is due to the massive presence of the neuronal cell bodies. On the other hand, the so-called white matter beneath this external sheet corresponds to the brain <em>wiring</em> connecting cells from different regions over the neocortex. The regions are typically connected hierarchically such that sensorial regions and high reasoning regions correspond respectively to lower levels and to higher levels in this hierarchy.</p>
<p>The basic computational unit of the brain is the biological neuron cell. There are several types of neuron cells, but they share a basic anatomy. Biological neurons have tree main parts: a main body a.k.a. soma, a dendrite tree and an axon. The <strong>dendrites</strong> make a lot of connections a.k.a. synapses to other cells, the input neurons. The <strong>soma</strong> in turn integrates stimulus or spikes received from the input neurons and activates, i.e. generates a spike itself, when a certain threshold its achieved. Roughly speaking the neuron cell activates when multiple input spikes corresponding to a learned pattern reach its dendrites about the same time. Finally, the <strong>axon</strong> is coated with a fatty insulation sheath called myelin to allow neurons to efficiently transmit spikes over long distances. Eventually, cell spikes reach the dendrite trees of multiple neurons forming synapses with its axon terminals. Note though that, despite being widely used, this model is oversimplified. Some researches for example argue that proximal dendrites â€“ dendrites close to the soma â€“ and distal dendrites play a different role on neuronal activation <span id="id4">[]</span>.</p>
<div class="proof observation admonition" id="observation-0">
<p class="admonition-title"><span class="caption-number">Observation 3 </span></p>
<section class="observation-content" id="proof-content">
<p>A lot of data have been collected about the human brain. Researchers know a lot about the anatomy of the brain and the role that different regions of the neocortex play on specific tasks. However, up to today, no overall theory of the brain exists. There are some promising efforts in this direction. As an appetizer, refer to the work of Numenta company <span id="id5">[]</span>.</p>
</section>
</div></section>
<section id="artificial-neural-networks-anns">
<h2>Artificial neural networks (ANNs)<a class="headerlink" href="#artificial-neural-networks-anns" title="Permalink to this headline">#</a></h2>
<p>ANNs are computational / mathematical models biologically inspired by our limited understanding of how some mechanisms in the brain might work. Similar to the biological brain, they include multiple interconnected layers of computational units â€“ called artificial neurons â€“ that cooperate to perform a task. Despite a single artificial neuron is not able to perform a <em>complex task</em>, the <em>trained network</em> is able to. In this sense, <em>intelligent behavior</em>, i.e. being able to perform the task, is an emergent ability of the artificial network. Examples of challenging tasks are image processing e.g. classify objects on images and natural language processing e.g. voice recognition (speech-to-text), voice synthesis (text-to-speech) and translation (text-to-text). These are <em>apparently ease</em> tasks for the human brain, but it is very hard to explicitly design a computer program to solve them without using the machine learning approach, which consists of teaching a computer program to perform a task using data (typically, a lot of data is required).</p>
<p><a class="reference internal" href="#biological-neuron-fig"><span class="std std-numref">Fig. 37</span></a> and <a class="reference internal" href="#artificial-neuron-fig"><span class="std std-numref">Fig. 38</span></a> illustrate respectively a typical biological neuron and its artificial model counterpart. Note that the artificial neuron is an oversimplified model of the biological one. First of all, whereas the intensity of a biological neuron response is related to how frequently it spikes over time, the output of an artificial neuron â€“ associated with the index <span class="math notranslate nohighlight">\( j \)</span> in <a class="reference internal" href="#artificial-neuron-fig"><span class="std std-numref">Fig. 38</span></a> â€“ at any time is often represented by a real number <span class="math notranslate nohighlight">\( y_{j} \)</span>. Moreover, the strength of a biological synapse depends on several factors e.g. its proximity to the soma, while the strength of an artificial synapse is represented by a real number <span class="math notranslate nohighlight">\( w_{i,j} \)</span> which simply weights the value of the corresponding input <span class="math notranslate nohighlight">\( x_{i} \)</span> on the global activation of the <span class="math notranslate nohighlight">\( j \)</span>-th neuron. In this sense, the artificial neuron activation is just an affine transformation of its <span class="math notranslate nohighlight">\( n \)</span> inputs <div class="math notranslate nohighlight">
\[ a_{j} = \sum_{i=1}^{n} w_{i,j} x_{i}. \]</div>
 Note also that the biological neuron activation produces an electrical spike which depends in turn on several factors e.g. the time since the last spike produced by the cell. On the other hand, the output value of the artificial neuron is determined by a non-linear activation function <span class="math notranslate nohighlight">\(\phi:\mathbb{R} \rightarrow \mathbb{R} \)</span> such that <div class="math notranslate nohighlight">
\[ y_{j} = \phi(a_{j}). \]</div>
 Lastly, at the best of our knowledge, learning in the brain can be achieved by either strengthening or creating new biological synapses. On weighted ANNs, the network architecture and connections are often fixed and learning is achieved in turn by adapting the weights of the available artificial synapses.</p>
<figure class="align-left" id="biological-neuron-fig">
<a class="reference internal image-reference" href="_images/biological_neuron.png"><img alt="_images/biological_neuron.png" src="_images/biological_neuron.png" style="height: 320px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 37 </span><span class="caption-text">Biological neuron.</span><a class="headerlink" href="#biological-neuron-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-left" id="artificial-neuron-fig">
<a class="reference internal image-reference" href="_images/artificial_neuron.png"><img alt="_images/artificial_neuron.png" src="_images/artificial_neuron.png" style="height: 320px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 38 </span><span class="caption-text">Artificial neuron.</span><a class="headerlink" href="#artificial-neuron-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="proof remark admonition" id="remark-1">
<p class="admonition-title"><span class="caption-number">Remark 22 </span></p>
<section class="remark-content" id="proof-content">
<p>By performing complex tasks, ANNs are able to exhibit intelligent behavior. Eventually, a trained ANN would pass a Turing test designed to check whether that particular task was executed by a human or not. Note though that there is an endless debate between being truly intelligent and showing intelligent behavior. Refer to the Chinese Room experiment <span id="id6">[]</span> (just for curiosity, do not invest too much time there). For now, it suffices to say that we are intelligent even by showing no behavior at all e.g. while standing still paying attention to a lecture.</p>
</section>
</div><div class="admonition-see-also admonition">
<p class="admonition-title">See also</p>
<p>In the typical isolated learning paradigm <span id="id7">[]</span>, ANNs are designed and trained to execute a single, isolated task. Furthermore, in contrast with the human brain, ANNs are often not able to learn from new experiences. Specifically, once they are trained, its knowledge â€“ typically stored in the weights of the artificial synapses â€“ is frozen. Thus, after deployed, during the recall phase, artificial networks are not able to learn â€“ we mean update their weights â€“ from experience, i.e. by observing new input data. Lastly, learning to execute new tasks by accumulating new experiences is a widely research topic today known as continuous learning or lifelong learning. One of the challenges faced by continuous learning methods based on conventional ANNs is to adjust the network parameters (weights) to learn new tasks, while avoiding the catastrophic forgetting of previously learned tasks (refer to <span id="id8">[]</span> for an overview, but do not spend too much time there).</p>
</div>
<div class="proof remark admonition" id="remark-2">
<p class="admonition-title"><span class="caption-number">Remark 23 </span></p>
<section class="remark-content" id="proof-content">
<p>Recently, with the advances of deep neural networks â€“ ANNs with several hidden layers â€“, interesting results from literature show ANNs surpassing the human ability in several tasks. However, most of these results were obtained by designing and training ANNs to execute a single specific task. This is known as <em>narrow AI</em> as opposite to <em>general AI</em> in which an intelligent agent would be able to learn new tasks â€“ potentially any task that a human being can perform â€“ by accumulating / learning from previous experiences on the fly, for instance, by executing other tasks. Nevertheless, there is a heated debate today whether the humankind should left general AI to science fiction or not (see <span id="id9">[]</span>). For now, it suffices to think about some interesting inquiries: is there a limit on how intelligent an artificial agent can be? Conversely, which factors limit the human intelligence? Note that, compared to an ant, one can argue that our intelligence level is as high as Einsteinâ€™s intelligence. Specifically, all humans apparently exhibit the same level of intelligence w.r.t. any ant. The crucial question is: what is intelligence at all? Can we effectively measure it? Surprisingly, up to today, there is no overall consensus on how to answer those questions. Thus, let put the philosophical aspects aside and check how we can train and employ ANNs to solve practical problemsâ€¦</p>
</section>
</div></section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "None/None",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="neuralnets.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Neural Networks</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="neuralnets_comp_graphs.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Computational graphs</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Sibylle Hess and Stiven Dias<br/>
  
      &copy; Copyright 2022. Eindhoven University of Technology.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>