
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Analytic Solutions &#8212; Data Mining and Machine Learning Jupyter Book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=b4b7a797" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"diag": "\\mathrm{diag}", "tr": "\\mathrm{tr}", "argmin": "\\mathrm{arg\\,min}", "argmax": "\\mathrm{arg\\,max}", "sign": "\\mathrm{sign}", "softmax": "\\mathrm{softmax}", "vvec": ["\\mathbf{#1}", 1], "bm": ["{\\boldsymbol #1}", 1], "concat": "\\mathbin{{+}\\mspace{-8mu}{+}}"}, "preamble": "\\usepackage{arydshln}"}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'optimization_analytic';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Numerical Optimization" href="optimization_numerical.html" />
    <link rel="prev" title="Convex Optimization" href="optimization_convex.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Data Mining and Machine Learning Jupyter Book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Data Mining and Machine Learning Jupyter Book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to the Data Mining and Machine Learning Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="notation.html">Notation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="linalg.html">Linear Algebra</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="linalg_spaces.html">Vector Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="linalg_normed_vs.html">Normed Vector Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="linalg_exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="optimization.html">Optimization</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="optimization_problems.html">Optimization Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimization_convex.html">Convex Optimization</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Analytic Solutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimization_numerical.html">Numerical Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimization_gradients.html">Matrix Derivatives</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimization_exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="regression.html">Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="regression_objective.html">Regression Objective</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression_functions.html">Regression Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression_optimization.html">Minimizing the RSS</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression_bias_var.html">The Bias-Variance Tradeoff</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression_sparse.html">The Sparse Regression Task</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression_ridge.html">Ridge Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression_lasso.html">Lasso</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression_exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="classification.html">Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="classification_problem.html">Classification Objective</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_knn.html">K-Nearest Neighbor</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_naive_bayes.html">Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_decision_trees.html">Decision Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_random_forests.html">Random Forests</a></li>

<li class="toctree-l2"><a class="reference internal" href="classification_svms.html">Support Vector Machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_kernel_svm.html">Kernel SVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_evaluation.html">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="neuralnets.html">Neural Networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="neuralnets_intro.html">From Linear Models to Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="neuralnets_mlps.html">MLPs</a></li>
<li class="toctree-l2"><a class="reference internal" href="neuralnets_backprop.html">Backpropagation</a></li>
<li class="toctree-l2"><a class="reference internal" href="neuralnets_sgd.html">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="neuralnets_conv.html">Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="neuralnets_pooling.html">Pooling</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="dim_reduction.html">Dimensionality Reduction Techniques</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="dim_reduction_mf.html">Low Rank Matrix Factorization</a></li>
<li class="toctree-l2"><a class="reference internal" href="dim_reduction_pca.html">Principal Component Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="dim_reduction_exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="clustering.html">Clustering</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="clustering_k_means.html">k-Means</a></li>



<li class="toctree-l2"><a class="reference internal" href="clustering_k_means_mf.html">k-Means is MF</a></li>


<li class="toctree-l2"><a class="reference internal" href="clustering_kernel_kmeans.html">Kernel k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="clustering_spectral.html">Spectral Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="clustering_exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/tue-ml/book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/tue-ml/book/edit/main/optimization_analytic.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/tue-ml/book/issues/new?title=Issue%20on%20page%20%2Foptimization_analytic.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/optimization_analytic.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Analytic Solutions</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#finding-stationary-points-in-higher-dimensions">Finding Stationary Points in higher dimensions</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="analytic-solutions">
<h1>Analytic Solutions<a class="headerlink" href="#analytic-solutions" title="Link to this heading">#</a></h1>
<p>You probably know from your highschool math classes that every local minimizer <span class="math notranslate nohighlight">\(x_0\)</span> of a function <span class="math notranslate nohighlight">\(f:\mathbb{R}\rightarrow\mathbb{R}\)</span> is a stationary point: <span class="math notranslate nohighlight">\(\frac{d}{dx}f(x_0)=0\)</span>. This is known as the first order neccessary condition. This property is easily understood, considering that the derivative indicates the slope of a function at a specified point. If we have a real-valued minimizer, then the slope is zero at that minimizer. If the slope would be positive, then we can go to the left to decrease the function value further, and if the slope is negative, we can go to the right. By means of this property, we can identify all the candidates that could be minimizers. Maximizers and saddle points are stationary points too. With the second order neccessary condition, we can filter further the minimizers from the pool of candidates. The second order neccessary condition states that at a minimizer the second derivative is nonnegative <span class="math notranslate nohighlight">\(\frac{d^2}{dx^2}f(x_0)\geq 0\)</span>. The second derivative is the slope of the slope. If we have a minimizer, then the slope increases: first we go down, and then we go up. Hence, we need that the slope of the slope does at least not decrease.</p>
<div class="proof example admonition" id="example-0">
<p class="admonition-title"><span class="caption-number">Example 7 </span></p>
<section class="example-content" id="proof-content">
<p>Let’s have a look at a seemingly simple example. The function <span class="math notranslate nohighlight">\(f(x) = \frac14x^4 + \frac13x^3 -x^2\)</span> is plotted below and we see that there are two minimizers <span class="math notranslate nohighlight">\(x_1=-2\)</span> and <span class="math notranslate nohighlight">\(x_2=1\)</span>. The question is just if those are all minimizers, or if there is another one beyond the scope of what is plotted here.</p>
<div class="figure" style="text-align: center"><p><img  src="_images/tikz-b2427c92aa6d74085e15433b634dd01ad375d2b1.png" alt="Figure made with TikZ" /></p>
</div><p>To find all the minimizers of the function, we apply the first and second order neccessary condition. We compute the first and second derivative.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \frac{d}{dx} f(x) &amp;= x^3 + x^2 -2x \\
    \frac{d^2}{dx^2}f(x) &amp; = 3x^2 + 2x -2
\end{align*}\]</div>
<p>Now we solve the equation setting the first derivative to zero and get three stationary points:
<div class="math notranslate nohighlight">
\[\frac{d}{dx} f(x) =0 \quad \Leftrightarrow \quad x_1=-2, x_2 = 0, x_3=1\]</div>

Given the plot, we already know which of these are minimizers, but to conclude our example, we apply the second order sufficient condition to identify the local minimizers <span class="math notranslate nohighlight">\(x_1=-2\)</span> and <span class="math notranslate nohighlight">\(x_2=3\)</span>.</p>
<div class="math notranslate nohighlight">
\[\frac{d^2}{dx^2}f(-2)=6\geq 0,\quad \frac{d^2}{dx^2}f(0)=-2&lt; 0,\quad \frac{d^2}{dx^2}f(1)=3\geq 0 \]</div>
</section>
</div><section id="finding-stationary-points-in-higher-dimensions">
<h2>Finding Stationary Points in higher dimensions<a class="headerlink" href="#finding-stationary-points-in-higher-dimensions" title="Link to this heading">#</a></h2>
<p>The principles of the first and second order conditions can be generalized to functions <span class="math notranslate nohighlight">\(f:\mathbb{R}^d\rightarrow \mathbb{R}\)</span> mapping from a <span class="math notranslate nohighlight">\(d\)</span>-dimensional vector space to real values. The main difficulty is that we have now more to consider than just left and right when looking for a direction into which we could minimize the function further. In fact, any vector <span class="math notranslate nohighlight">\(\vvec{v}\in\mathbb{R}^d\)</span> could indicate a possible direction in which the function might decrease. Luckily, we can show that we just have to check one direction, given by the negative <em>gradient</em>, which points into the direction of steepest descent. The gradient indicates the slope of a function in the directions of the coordinates, which are called the <em>partial derivatives</em>. A partial derivative <span class="math notranslate nohighlight">\(\frac{\partial f(\vvec{x})}{\partial x_i}\)</span> is computed like a one-dimensional derivative by treating all variables except for <span class="math notranslate nohighlight">\(x_i\)</span> as  a constant. The gradient gathers those partial derivatives in a vector. The transposed of the gradient is called the <em>Jacobian</em>.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \frac{\partial f(\vvec{x})}{\partial \vvec{x}} &amp;=
    \begin{pmatrix}
    \frac{\partial f(\vvec{x})}{\partial x_1} &amp; \ldots &amp; \frac{\partial f(\vvec{x})}{\partial x_d}
    \end{pmatrix}\in\mathbb{R}^{1\times d} &amp;\text{(Jacobian)}\\
      \nabla_\vvec{x} f(\vvec{x}) &amp;=
    \begin{pmatrix}
    \frac{\partial f(\vvec{x})}{\partial x_1} \\ \vdots \\ \frac{\partial f(\vvec{x})}{\partial x_d}
    \end{pmatrix}\in\mathbb{R}^{d} &amp;\text{(Gradient)}
\end{align*}\]</div>
<p>With the gradient, we get a first order neccessary condition (FONC) for functions mapping from a vector space <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>.</p>
<div class="proof theorem admonition" id="theorem-1">
<p class="admonition-title"><span class="caption-number">Theorem 6 </span> (FONC)</p>
<section class="theorem-content" id="proof-content">
<p>If <span class="math notranslate nohighlight">\(\vvec{x}\)</span> is a local  minimizer of <span class="math notranslate nohighlight">\(f:\mathbb{R}^d\rightarrow\mathbb{R}\)</span> and <span class="math notranslate nohighlight">\(f\)</span> is continuously
differentiable in an open neighborhood of <span class="math notranslate nohighlight">\(\vvec{x}\)</span>, then
<div class="math notranslate nohighlight">
\[\nabla f(\vvec{x})=0\]</div>
</p>
</section>
</div><p>Likewise, a vector <span class="math notranslate nohighlight">\(\vvec{x}\)</span> is called <em>stationary point</em> if <span class="math notranslate nohighlight">\(\nabla f(\vvec{x})=0\)</span>. The second order neccessary condition (SONC) uses the generation of the second order derivative to vector spaces, called the <em>Hessian</em>. We state this condition here for reasons of completeness, but we will not need this property for the machine learning models that we discuss in this course.</p>
<div class="proof theorem admonition" id="theorem-2">
<p class="admonition-title"><span class="caption-number">Theorem 7 </span> (SONC)</p>
<section class="theorem-content" id="proof-content">
<p>If <span class="math notranslate nohighlight">\(\vvec{x}\)</span> is a local  minimizer of <span class="math notranslate nohighlight">\(f:\mathbb{R}^d\rightarrow\mathbb{R}\)</span> and <span class="math notranslate nohighlight">\(\nabla^2f\)</span> is continuous in an open
neighborhood of <span class="math notranslate nohighlight">\(\vvec{x}\)</span>, then
<div class="math notranslate nohighlight">
\[\nabla f(\vvec{x})=0 \text{ and } \nabla^2f(\vvec{x}) \text{ is positive semidefinite}\]</div>
</p>
</section>
</div><p>A matrix <span class="math notranslate nohighlight">\(A\in\mathbb{R}^{d\times d}\)</span> is <strong>positive semidefinite</strong> if
<div class="math notranslate nohighlight">
\[\vvec{x}^\top A \vvec{x}\geq 0 \text{ for all } \vvec{x}\in\mathbb{R}^d\]</div>
</p>
<div class="proof example admonition" id="expl_fonc">
<p class="admonition-title"><span class="caption-number">Example 8 </span></p>
<section class="example-content" id="proof-content">
<figure class="align-left" id="rosenbrock">
<a class="reference internal image-reference" href="_images/rosenbrock.png"><img alt="_images/rosenbrock.png" src="_images/rosenbrock.png" style="height: 200px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">The Rosenbrock function</span><a class="headerlink" href="#rosenbrock" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>In this example we apply FONC and SONC to find the minimizers of the Rosenbrock function, which is given by</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    f(\vvec{x})&amp;= 100(x_2-x_1^2)^2 +(1-x_1)^2.
\end{align*}\]</div>
<p>In order to apply FONC, we need to compute the gradient. We do so by computing the partial derivatives. The partial derivatives are computed by the same rules as you know it from computing the derivative of a one-dimensional function.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \frac{\partial}{\partial x_1}f(\vvec{x})&amp;= 400x_1(x_1^2-x_2) +2(x_1-1)\\
    \frac{\partial}{\partial x_2}f(\vvec{x})&amp;= 200(x_2-x_1^2)
\end{align*}\]</div>
<p>FONC says that every minimizer has to be a stationary point. Stationary points are the vectors at which the gradient of <span class="math notranslate nohighlight">\(f\)</span> is zero. We compute the set of stationary points by setting the gradient to zero and solving for <span class="math notranslate nohighlight">\(\vvec{x}\)</span>.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
      \frac{\partial}{\partial x_2}f(\vvec{x})&amp;=200(x_2-x_1^2)=0
      &amp;\Leftrightarrow x_2 =x_1^2\\
      \frac{\partial}{\partial x_1}f\begin{pmatrix}x_1\\x_1^2\end{pmatrix}&amp;= 2(x_1-1) =0 
      &amp;\Leftrightarrow x_1=1
\end{align*}\]</div>
<p>According to FONC we have a stationary point at <span class="math notranslate nohighlight">\(\vvec{x}=(1,1)\)</span>. Now we check with SONC if the stationary point could be a minimizer (it could also be a maximizer or a saddle point). SONC says that every minimizer has a positive definite Hessian. Hence, we require the Hessian, the second derivative of the Rosenbrock function. To that end, we compute the partial derivatives of the partial derivatives:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\frac{\partial^2}{\partial^2 x_1}f(\vvec{x})&amp;= \frac{\partial}{\partial x_1}\left(\frac{\partial}{\partial x_1}f(\vvec{x})\right)= 1200x_1^2-400x_2 +2\\
\frac{\partial^2}{\partial^2 x_2}f(\vvec{x})&amp;=  \frac{\partial}{\partial x_2} \left(\frac{\partial}{\partial x_2}f(\vvec{x})\right)= 200\\
\frac{\partial^2}{\partial x_1\partial x_2}f(\vvec{x})&amp;=\frac{\partial^2}{\partial x_2\partial x_1}f(\vvec{x})= -400x_1
\end{align*}\]</div>
<p>The Hessian is given by</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \nabla^2 f(\vvec{x})&amp;=  \begin{pmatrix}\frac{\partial^2}{\partial^2 x_1} f(\vvec{x}) &amp; \frac{\partial^2}{\partial x_1x_2} f(\vvec{x})\\ \frac{\partial^2}{\partial x_2x_1}f(\vvec{x}) &amp; \frac{\partial^2}{\partial^2 x_2} f(\vvec{x})\end{pmatrix}\\
    &amp;=200\begin{pmatrix} 6x_1^2-2x_2 + 0.01&amp; -2x_1\\ -2x_1 &amp;1 \end{pmatrix}
\end{align*}\]</div>
<p>We insert our stationary point <span class="math notranslate nohighlight">\(\vvec{x}_0=(1,1)\)</span> into the Hessian and get
<div class="math notranslate nohighlight">
\[\begin{split}\nabla^2f(\vvec{x}_0)= 200\begin{pmatrix} 4.01&amp; -2\\ -2 &amp; 1\end{pmatrix}\end{split}\]</div>

Now we check if the Hessian at the stationary point is positive definite. Let <span class="math notranslate nohighlight">\(\vvec{x}\in\mathbb{R}^2\)</span>, then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \vvec{x}^\top \nabla^2f(\vvec{x}_0) \vvec{x} &amp;= 200 \begin{pmatrix}x_1 &amp; x_2\end{pmatrix} \begin{pmatrix}
     4.01&amp; -2\\ -2 &amp; 1
    \end{pmatrix}\begin{pmatrix}x_1\\x_2\end{pmatrix}\\
    &amp;= 200\begin{pmatrix}x_1 &amp; x_2\end{pmatrix} \begin{pmatrix}
    4.01x_1-2x_2\\ -2x_1+ x_2
    \end{pmatrix}\\
    &amp;=200(4.01x_1^2 -2x_1x_2 -2x_1x_2 +x_2^2)\\
    &amp;= 200(4.01x_1^2 -4x_1x_2 + x_2^2)\\
    &amp;= 200((2x_1-x_2)^2 +0.01x_1^2) \geq 0
\end{align*}\]</div>
<p>The last inequality follows because the sum of quadratic terms can not be negative.
We conclude that the Hessian at our stationary point is positive semi-definite. As a result, FONC and SONC yield that <span class="math notranslate nohighlight">\(\vvec{x}=(1,1)\)</span> is the only possible local minimizer of <span class="math notranslate nohighlight">\(f\)</span>.</p>
</section>
</div><p>Nice, we have now a strategy yo find local minimizers if we have an unconstrained objective with an objective function which is continuously differentiable. Let’s consider a more complex setting, introducing constraints.</p>
<div class="proof example admonition" id="example-4">
<p class="admonition-title"><span class="caption-number">Example 9 </span> (Solving of a dual)</p>
<section class="example-content" id="proof-content">
<p>We solve the following constrained optimization problem:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\min_{\vvec{w}}\ &amp; w_1^2+w_2^2\\
\text{ s.t } &amp; w_2\geq 1\\
&amp; w_2\geq -w_1+2
\end{align*}\]</div>
<p>Geometrically, the problem looks as follows:</p>
<div class="figure" style="text-align: center"><p><img  src="_images/tikz-cf5cfbed76215bcf3226e9812b672d701d6d3e91.png" alt="Figure made with TikZ" /></p>
</div><p>We have an objective function that is visualized over the level sets (the rings). Each ring indicates the vectors <span class="math notranslate nohighlight">\(\vvec{w}\)</span> that return the same function value. We see that the minimum is at <span class="math notranslate nohighlight">\((0,0)\)</span>, but that minimum does not lie in the feasible set <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>.</p>
<p>To solve this constrained objective, we formulate the dual, which requires the Lagrangian first. To formulate the Lagrangian, we put the constraints into the form <span class="math notranslate nohighlight">\(g(\vvec{w})\geq 0\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
w_2-1&amp;\geq 0\\
w_2+w_1-2 &amp;\geq 0
\end{align*}\]</div>
<p>The Lagrangian is then given by
<div class="math notranslate nohighlight">
\[\mathcal{L}(\vvec{w},\bm{\lambda})=w_1^2 +w_2^2 -\lambda_1(w_2-1)-\lambda_2(w_2+w_1-2)\]</div>

The dual objective function returns the minimum of the Lagrangian:
<div class="math notranslate nohighlight">
\[\mathcal{L}_{dual}=\min_{\vvec{x}}\mathcal{L}(\vvec{w},\bm{\lambda}).\]</div>

We can compute the dual objective function analytically over the stationary point, since the Lagrangian is convex in <span class="math notranslate nohighlight">\(\vvec{w}\)</span> (it is the sum of convex functions: the squared norm and affine functions). Hence, we compute the gradient and set it to zero.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\nabla_\vvec{w}\mathcal{L}(\vvec{w},\bm{\lambda}) &amp;= \begin{pmatrix}
2w_1-\lambda_2\\
2w_2-\lambda_1-\lambda_2
\end{pmatrix}
=\begin{pmatrix}
0\\ 0
\end{pmatrix}
\Leftrightarrow &amp; \begin{cases}
w_1 = \frac12 \lambda_2\\
w_2 = \frac12 \lambda_1 + \frac12 \lambda_2.
\end{cases}
\end{align*}\]</div>
<p>We plug in the minimizer <span class="math notranslate nohighlight">\(\vvec{w}\)</span> defined above in the Lagrangian and obtain the dual objective function:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathcal{L}_{dual}(\bm{\lambda}) &amp;= -\frac14 \lambda_1^2-\frac12 \lambda_2^2 -\frac12\lambda_1\lambda_2 + \lambda_1 +2\lambda_2.
\end{align*}\]</div>
<p>Hence, we need to maximize the function above, which is equivalent to minimizing the negative dual function. The negative dual function is convex, since it can be written as</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
-\mathcal{L}_{dual}(\bm{\lambda}) &amp;= \frac14\left\lVert \begin{pmatrix}1 &amp; 1\\0 &amp; 1\end{pmatrix}\bm{\lambda}\right\rVert^2 - \begin{pmatrix}1 &amp;2 \end{pmatrix}\bm{\lambda}
\end{align*} \]</div>
<p>which is the sum of a convex and an affine function. Hence, to solve the dual objective, we set again the gradient to zero:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
-\nabla\mathcal{L}_{dual}(\bm{\lambda}) = \begin{pmatrix}\frac12\lambda_1 +\frac12\lambda_2-1\\ 
\frac12\lambda_1+\lambda_2-2\end{pmatrix} = \vvec{0} 
\end{align*}\]</div>
<p>which is the case for <span class="math notranslate nohighlight">\(\lambda_1=0\)</span> and <span class="math notranslate nohighlight">\(\lambda_2=2\)</span>. To get the solution nof our primal objective, we plug in the optimal <span class="math notranslate nohighlight">\(\bm{\lambda}\)</span> in the optimal <span class="math notranslate nohighlight">\(\vvec{w}\)</span> definition and get</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
w_1^* &amp;= \frac12\lambda_2^* = 1\\
w_2^* &amp;= \frac12\lambda_1^* +\frac12\lambda_2^* = 1
\end{align*}\]</div>
</section>
</div></section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="optimization_convex.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Convex Optimization</p>
      </div>
    </a>
    <a class="right-next"
       href="optimization_numerical.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Numerical Optimization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#finding-stationary-points-in-higher-dimensions">Finding Stationary Points in higher dimensions</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Sibylle Hess
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022. Eindhoven University of Technology.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>